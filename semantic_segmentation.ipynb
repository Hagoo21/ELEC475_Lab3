{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pascal VOC Dataset - Exploratory Data Analysis (EDA)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET\n",
        "from collections import Counter, defaultdict\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for better visualizations\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Dataset Overview and Setup\n",
        "\n",
        "# Pascal VOC 2012 dataset paths\n",
        "VOC_ROOT = './data/VOCdevkit/VOC2012'\n",
        "IMAGES_DIR = os.path.join(VOC_ROOT, 'JPEGImages')\n",
        "ANNOTATIONS_DIR = os.path.join(VOC_ROOT, 'Annotations')\n",
        "SEGMENTATION_CLASS_DIR = os.path.join(VOC_ROOT, 'SegmentationClass')\n",
        "SEGMENTATION_OBJECT_DIR = os.path.join(VOC_ROOT, 'SegmentationObject')\n",
        "IMAGESETS_DIR = os.path.join(VOC_ROOT, 'ImageSets', 'Segmentation')\n",
        "\n",
        "# Pascal VOC class names (20 object classes + background)\n",
        "VOC_CLASSES = [\n",
        "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', \n",
        "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', \n",
        "    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
        "]\n",
        "\n",
        "# Color palette for visualization (RGB)\n",
        "VOC_COLORMAP = [\n",
        "    [0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128],\n",
        "    [128, 0, 128], [0, 128, 128], [128, 128, 128], [64, 0, 0], [192, 0, 0],\n",
        "    [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128], [64, 128, 128],\n",
        "    [192, 128, 128], [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
        "    [0, 64, 128]\n",
        "]\n",
        "\n",
        "print(\"Pascal VOC 2012 Dataset Paths:\")\n",
        "print(f\"Root: {VOC_ROOT}\")\n",
        "print(f\"Images: {IMAGES_DIR}\")\n",
        "print(f\"Annotations: {ANNOTATIONS_DIR}\")\n",
        "print(f\"Segmentation Masks: {SEGMENTATION_CLASS_DIR}\")\n",
        "print(f\"\\nNumber of classes: {len(VOC_CLASSES)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Load Dataset Splits\n",
        "\n",
        "def load_image_ids(split='train'):\n",
        "    \"\"\"Load image IDs for a given split (train/val/trainval)\"\"\"\n",
        "    split_file = os.path.join(IMAGESETS_DIR, f'{split}.txt')\n",
        "    if os.path.exists(split_file):\n",
        "        with open(split_file, 'r') as f:\n",
        "            return [line.strip() for line in f.readlines()]\n",
        "    return []\n",
        "\n",
        "# Load all splits\n",
        "train_ids = load_image_ids('train')\n",
        "val_ids = load_image_ids('val')\n",
        "trainval_ids = load_image_ids('trainval')\n",
        "\n",
        "print(\"Dataset Split Information:\")\n",
        "print(f\"Training set: {len(train_ids)} images\")\n",
        "print(f\"Validation set: {len(val_ids)} images\")\n",
        "print(f\"Train+Val set: {len(trainval_ids)} images\")\n",
        "print(f\"\\nExample image IDs: {train_ids[:5]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Analyze Image Dimensions\n",
        "\n",
        "def get_image_dimensions(image_ids, max_samples=None):\n",
        "    \"\"\"Get dimensions of images in the dataset\"\"\"\n",
        "    dimensions = []\n",
        "    if max_samples:\n",
        "        image_ids = image_ids[:max_samples]\n",
        "    \n",
        "    for img_id in image_ids:\n",
        "        img_path = os.path.join(IMAGES_DIR, f'{img_id}.jpg')\n",
        "        if os.path.exists(img_path):\n",
        "            img = Image.open(img_path)\n",
        "            dimensions.append(img.size)  # (width, height)\n",
        "    return dimensions\n",
        "\n",
        "# Analyze dimensions for training set (sample for speed)\n",
        "print(\"Analyzing image dimensions...\")\n",
        "dimensions = get_image_dimensions(train_ids, max_samples=500)\n",
        "\n",
        "widths = [d[0] for d in dimensions]\n",
        "heights = [d[1] for d in dimensions]\n",
        "aspect_ratios = [w/h for w, h in dimensions]\n",
        "\n",
        "print(f\"\\nImage Dimensions Statistics (based on {len(dimensions)} samples):\")\n",
        "print(f\"Width  - Min: {min(widths)}, Max: {max(widths)}, Mean: {np.mean(widths):.1f}\")\n",
        "print(f\"Height - Min: {min(heights)}, Max: {max(heights)}, Mean: {np.mean(heights):.1f}\")\n",
        "print(f\"Aspect Ratio - Min: {min(aspect_ratios):.2f}, Max: {max(aspect_ratios):.2f}, Mean: {np.mean(aspect_ratios):.2f}\")\n",
        "\n",
        "# Visualize dimensions\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "axes[0].hist(widths, bins=30, edgecolor='black', alpha=0.7)\n",
        "axes[0].set_xlabel('Width (pixels)')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_title('Distribution of Image Widths')\n",
        "\n",
        "axes[1].hist(heights, bins=30, edgecolor='black', alpha=0.7)\n",
        "axes[1].set_xlabel('Height (pixels)')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].set_title('Distribution of Image Heights')\n",
        "\n",
        "axes[2].hist(aspect_ratios, bins=30, edgecolor='black', alpha=0.7)\n",
        "axes[2].set_xlabel('Aspect Ratio (W/H)')\n",
        "axes[2].set_ylabel('Frequency')\n",
        "axes[2].set_title('Distribution of Aspect Ratios')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Analyze Segmentation Masks - Class Distribution\n",
        "\n",
        "def analyze_segmentation_mask(mask_path):\n",
        "    \"\"\"Analyze a single segmentation mask and return class counts\"\"\"\n",
        "    mask = Image.open(mask_path)\n",
        "    mask_array = np.array(mask)\n",
        "    \n",
        "    # Get unique classes (excluding 255 which is the boundary/ignore class)\n",
        "    unique_classes = np.unique(mask_array)\n",
        "    unique_classes = unique_classes[unique_classes != 255]\n",
        "    \n",
        "    # Count pixels per class\n",
        "    class_pixels = {}\n",
        "    for cls in unique_classes:\n",
        "        class_pixels[cls] = np.sum(mask_array == cls)\n",
        "    \n",
        "    return unique_classes, class_pixels\n",
        "\n",
        "# Analyze class distribution across training set (sample for speed)\n",
        "print(\"Analyzing segmentation masks...\")\n",
        "class_counts = Counter()\n",
        "image_class_presence = defaultdict(int)  # How many images contain each class\n",
        "total_masks_analyzed = 0\n",
        "\n",
        "for img_id in train_ids[:500]:  # Sample 500 images\n",
        "    mask_path = os.path.join(SEGMENTATION_CLASS_DIR, f'{img_id}.png')\n",
        "    if os.path.exists(mask_path):\n",
        "        unique_classes, class_pixels = analyze_segmentation_mask(mask_path)\n",
        "        \n",
        "        # Count total occurrences\n",
        "        for cls in unique_classes:\n",
        "            class_counts[cls] += 1\n",
        "            \n",
        "        total_masks_analyzed += 1\n",
        "\n",
        "print(f\"\\nAnalyzed {total_masks_analyzed} segmentation masks\")\n",
        "print(f\"Number of unique classes found: {len(class_counts)}\")\n",
        "\n",
        "# Create visualization\n",
        "class_names = [VOC_CLASSES[cls] for cls in sorted(class_counts.keys())]\n",
        "class_frequencies = [class_counts[cls] for cls in sorted(class_counts.keys())]\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "bars = plt.bar(range(len(class_names)), class_frequencies, edgecolor='black', alpha=0.7)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images Containing Class')\n",
        "plt.title(f'Class Distribution in Segmentation Masks (Sample of {total_masks_analyzed} images)')\n",
        "plt.xticks(range(len(class_names)), class_names, rotation=45, ha='right')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Color bars by class\n",
        "for i, bar in enumerate(bars):\n",
        "    cls_idx = sorted(class_counts.keys())[i]\n",
        "    if cls_idx < len(VOC_COLORMAP):\n",
        "        bar.set_color([c/255.0 for c in VOC_COLORMAP[cls_idx]])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print top 10 most common classes\n",
        "print(\"\\nTop 10 Most Common Classes:\")\n",
        "for i, (cls, count) in enumerate(class_counts.most_common(10), 1):\n",
        "    print(f\"{i}. {VOC_CLASSES[cls]}: {count} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualize Sample Images with Segmentation Masks\n",
        "\n",
        "def visualize_sample(img_id, show_colorful=True):\n",
        "    \"\"\"Visualize an image alongside its segmentation mask\"\"\"\n",
        "    img_path = os.path.join(IMAGES_DIR, f'{img_id}.jpg')\n",
        "    mask_path = os.path.join(SEGMENTATION_CLASS_DIR, f'{img_id}.png')\n",
        "    \n",
        "    if not os.path.exists(img_path) or not os.path.exists(mask_path):\n",
        "        return None, None\n",
        "    \n",
        "    img = Image.open(img_path)\n",
        "    mask = Image.open(mask_path)\n",
        "    mask_array = np.array(mask)\n",
        "    \n",
        "    # Get unique classes in this mask\n",
        "    unique_classes = np.unique(mask_array)\n",
        "    unique_classes = unique_classes[unique_classes != 255]\n",
        "    \n",
        "    # Create colored mask\n",
        "    if show_colorful:\n",
        "        colored_mask = np.zeros((*mask_array.shape, 3), dtype=np.uint8)\n",
        "        for cls in unique_classes:\n",
        "            if cls < len(VOC_COLORMAP):\n",
        "                colored_mask[mask_array == cls] = VOC_COLORMAP[cls]\n",
        "    \n",
        "    return img, (colored_mask if show_colorful else mask_array), unique_classes\n",
        "\n",
        "# Visualize multiple samples\n",
        "n_samples = 6\n",
        "sample_ids = train_ids[:n_samples]\n",
        "\n",
        "fig, axes = plt.subplots(n_samples, 3, figsize=(15, 4*n_samples))\n",
        "\n",
        "for i, img_id in enumerate(sample_ids):\n",
        "    img, mask, unique_classes = visualize_sample(img_id)\n",
        "    \n",
        "    if img is not None:\n",
        "        # Original image\n",
        "        axes[i, 0].imshow(img)\n",
        "        axes[i, 0].set_title(f'Original Image: {img_id}')\n",
        "        axes[i, 0].axis('off')\n",
        "        \n",
        "        # Segmentation mask (colored)\n",
        "        axes[i, 1].imshow(mask)\n",
        "        axes[i, 1].set_title('Segmentation Mask (Colored)')\n",
        "        axes[i, 1].axis('off')\n",
        "        \n",
        "        # Overlay\n",
        "        axes[i, 2].imshow(img)\n",
        "        axes[i, 2].imshow(mask, alpha=0.5)\n",
        "        axes[i, 2].set_title('Overlay')\n",
        "        axes[i, 2].axis('off')\n",
        "        \n",
        "        # Print classes present\n",
        "        class_names = [VOC_CLASSES[cls] for cls in unique_classes if cls < len(VOC_CLASSES)]\n",
        "        print(f\"{img_id}: {', '.join(class_names)}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. Pixel-Level Class Distribution\n",
        "\n",
        "def calculate_pixel_distribution(image_ids, max_samples=200):\n",
        "    \"\"\"Calculate the distribution of pixels across all classes\"\"\"\n",
        "    pixel_counts = defaultdict(int)\n",
        "    total_pixels = 0\n",
        "    \n",
        "    for img_id in image_ids[:max_samples]:\n",
        "        mask_path = os.path.join(SEGMENTATION_CLASS_DIR, f'{img_id}.png')\n",
        "        if os.path.exists(mask_path):\n",
        "            mask = np.array(Image.open(mask_path))\n",
        "            \n",
        "            # Count pixels for each class\n",
        "            unique, counts = np.unique(mask, return_counts=True)\n",
        "            for cls, count in zip(unique, counts):\n",
        "                if cls != 255:  # Ignore boundary class\n",
        "                    pixel_counts[cls] += count\n",
        "                    total_pixels += count\n",
        "    \n",
        "    return pixel_counts, total_pixels\n",
        "\n",
        "print(\"Calculating pixel-level class distribution...\")\n",
        "pixel_counts, total_pixels = calculate_pixel_distribution(train_ids, max_samples=300)\n",
        "\n",
        "# Calculate percentages\n",
        "class_percentages = {cls: (count / total_pixels) * 100 for cls, count in pixel_counts.items()}\n",
        "\n",
        "# Sort by percentage\n",
        "sorted_classes = sorted(class_percentages.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Visualize\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Bar plot\n",
        "classes = [VOC_CLASSES[cls] for cls, _ in sorted_classes]\n",
        "percentages = [pct for _, pct in sorted_classes]\n",
        "\n",
        "bars = ax1.barh(range(len(classes)), percentages, edgecolor='black', alpha=0.7)\n",
        "ax1.set_yticks(range(len(classes)))\n",
        "ax1.set_yticklabels(classes)\n",
        "ax1.set_xlabel('Percentage of Total Pixels (%)')\n",
        "ax1.set_title('Pixel Distribution Across Classes')\n",
        "ax1.invert_yaxis()\n",
        "\n",
        "# Color bars\n",
        "for i, (cls, _) in enumerate(sorted_classes):\n",
        "    if cls < len(VOC_COLORMAP):\n",
        "        bars[i].set_color([c/255.0 for c in VOC_COLORMAP[cls]])\n",
        "\n",
        "# Pie chart for top classes\n",
        "top_n = 10\n",
        "top_classes = sorted_classes[:top_n]\n",
        "other_pct = sum(pct for _, pct in sorted_classes[top_n:])\n",
        "\n",
        "pie_labels = [VOC_CLASSES[cls] for cls, _ in top_classes]\n",
        "pie_values = [pct for _, pct in top_classes]\n",
        "\n",
        "if other_pct > 0:\n",
        "    pie_labels.append('Others')\n",
        "    pie_values.append(other_pct)\n",
        "\n",
        "ax2.pie(pie_values, labels=pie_labels, autopct='%1.1f%%', startangle=90)\n",
        "ax2.set_title(f'Top {top_n} Classes by Pixel Coverage')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nTotal pixels analyzed: {total_pixels:,}\")\n",
        "print(\"\\nTop 5 classes by pixel coverage:\")\n",
        "for i, (cls, pct) in enumerate(sorted_classes[:5], 1):\n",
        "    print(f\"{i}. {VOC_CLASSES[cls]}: {pct:.2f}% ({pixel_counts[cls]:,} pixels)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. Object Co-occurrence Analysis\n",
        "\n",
        "def analyze_class_cooccurrence(image_ids, max_samples=300):\n",
        "    \"\"\"Analyze which classes tend to appear together in images\"\"\"\n",
        "    cooccurrence_matrix = np.zeros((len(VOC_CLASSES), len(VOC_CLASSES)), dtype=int)\n",
        "    \n",
        "    for img_id in image_ids[:max_samples]:\n",
        "        mask_path = os.path.join(SEGMENTATION_CLASS_DIR, f'{img_id}.png')\n",
        "        if os.path.exists(mask_path):\n",
        "            mask = np.array(Image.open(mask_path))\n",
        "            unique_classes = np.unique(mask)\n",
        "            unique_classes = unique_classes[unique_classes != 255]\n",
        "            \n",
        "            # Update co-occurrence matrix\n",
        "            for i, cls1 in enumerate(unique_classes):\n",
        "                for cls2 in unique_classes:\n",
        "                    if cls1 < len(VOC_CLASSES) and cls2 < len(VOC_CLASSES):\n",
        "                        cooccurrence_matrix[cls1, cls2] += 1\n",
        "    \n",
        "    return cooccurrence_matrix\n",
        "\n",
        "print(\"Analyzing class co-occurrence...\")\n",
        "cooccurrence = analyze_class_cooccurrence(train_ids, max_samples=300)\n",
        "\n",
        "# Normalize by diagonal (how often each class appears)\n",
        "diagonal = np.diag(cooccurrence).copy()\n",
        "normalized_cooccurrence = np.zeros_like(cooccurrence, dtype=float)\n",
        "\n",
        "for i in range(len(VOC_CLASSES)):\n",
        "    for j in range(len(VOC_CLASSES)):\n",
        "        if diagonal[i] > 0:\n",
        "            normalized_cooccurrence[i, j] = cooccurrence[i, j] / diagonal[i]\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(14, 12))\n",
        "sns.heatmap(normalized_cooccurrence, \n",
        "            xticklabels=VOC_CLASSES, \n",
        "            yticklabels=VOC_CLASSES,\n",
        "            cmap='YlOrRd', \n",
        "            annot=False, \n",
        "            fmt='.2f',\n",
        "            cbar_kws={'label': 'Co-occurrence Probability'})\n",
        "plt.title('Class Co-occurrence Matrix\\n(Probability that column class appears when row class is present)')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Class')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print interesting co-occurrences (excluding self)\n",
        "print(\"\\nTop 10 Class Pairs that Often Appear Together:\")\n",
        "pairs = []\n",
        "for i in range(len(VOC_CLASSES)):\n",
        "    for j in range(i+1, len(VOC_CLASSES)):\n",
        "        if diagonal[i] > 0 and diagonal[j] > 0:\n",
        "            avg_prob = (cooccurrence[i, j] / diagonal[i] + cooccurrence[j, i] / diagonal[j]) / 2\n",
        "            pairs.append((VOC_CLASSES[i], VOC_CLASSES[j], avg_prob, cooccurrence[i, j]))\n",
        "\n",
        "pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "for i, (cls1, cls2, prob, count) in enumerate(pairs[:10], 1):\n",
        "    print(f\"{i}. {cls1} â†” {cls2}: {prob:.2%} co-occurrence ({count} times)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. Segmentation Complexity Analysis\n",
        "\n",
        "def analyze_segmentation_complexity(image_ids, max_samples=300):\n",
        "    \"\"\"Analyze the complexity of segmentation masks\"\"\"\n",
        "    num_classes_per_image = []\n",
        "    num_objects_per_image = []\n",
        "    \n",
        "    for img_id in image_ids[:max_samples]:\n",
        "        mask_path = os.path.join(SEGMENTATION_CLASS_DIR, f'{img_id}.png')\n",
        "        obj_mask_path = os.path.join(SEGMENTATION_OBJECT_DIR, f'{img_id}.png')\n",
        "        \n",
        "        if os.path.exists(mask_path):\n",
        "            # Count unique classes\n",
        "            mask = np.array(Image.open(mask_path))\n",
        "            unique_classes = np.unique(mask)\n",
        "            unique_classes = unique_classes[unique_classes != 255]\n",
        "            num_classes_per_image.append(len(unique_classes))\n",
        "            \n",
        "            # Count unique objects\n",
        "            if os.path.exists(obj_mask_path):\n",
        "                obj_mask = np.array(Image.open(obj_mask_path))\n",
        "                unique_objects = np.unique(obj_mask)\n",
        "                unique_objects = unique_objects[unique_objects != 255]\n",
        "                unique_objects = unique_objects[unique_objects != 0]  # Exclude background\n",
        "                num_objects_per_image.append(len(unique_objects))\n",
        "    \n",
        "    return num_classes_per_image, num_objects_per_image\n",
        "\n",
        "print(\"Analyzing segmentation complexity...\")\n",
        "num_classes_per_img, num_objects_per_img = analyze_segmentation_complexity(train_ids, max_samples=300)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Distribution of number of classes per image\n",
        "axes[0].hist(num_classes_per_img, bins=range(1, max(num_classes_per_img)+2), \n",
        "             edgecolor='black', alpha=0.7)\n",
        "axes[0].set_xlabel('Number of Classes per Image')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_title('Distribution of Classes per Image')\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Distribution of number of objects per image\n",
        "if num_objects_per_img:\n",
        "    axes[1].hist(num_objects_per_img, bins=range(1, max(num_objects_per_img)+2), \n",
        "                 edgecolor='black', alpha=0.7, color='coral')\n",
        "    axes[1].set_xlabel('Number of Objects per Image')\n",
        "    axes[1].set_ylabel('Frequency')\n",
        "    axes[1].set_title('Distribution of Object Instances per Image')\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nClasses per Image:\")\n",
        "print(f\"  Mean: {np.mean(num_classes_per_img):.2f}\")\n",
        "print(f\"  Median: {np.median(num_classes_per_img):.2f}\")\n",
        "print(f\"  Min: {min(num_classes_per_img)}, Max: {max(num_classes_per_img)}\")\n",
        "\n",
        "if num_objects_per_img:\n",
        "    print(f\"\\nObjects per Image:\")\n",
        "    print(f\"  Mean: {np.mean(num_objects_per_img):.2f}\")\n",
        "    print(f\"  Median: {np.median(num_objects_per_img):.2f}\")\n",
        "    print(f\"  Min: {min(num_objects_per_img)}, Max: {max(num_objects_per_img)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 9. Object Size Analysis\n",
        "\n",
        "def analyze_object_sizes(image_ids, max_samples=200):\n",
        "    \"\"\"Analyze the relative size of objects in images\"\"\"\n",
        "    class_sizes = defaultdict(list)  # List of relative sizes (% of image) per class\n",
        "    \n",
        "    for img_id in image_ids[:max_samples]:\n",
        "        mask_path = os.path.join(SEGMENTATION_CLASS_DIR, f'{img_id}.png')\n",
        "        if os.path.exists(mask_path):\n",
        "            mask = np.array(Image.open(mask_path))\n",
        "            total_pixels = mask.size\n",
        "            \n",
        "            unique_classes = np.unique(mask)\n",
        "            unique_classes = unique_classes[unique_classes != 255]\n",
        "            unique_classes = unique_classes[unique_classes != 0]  # Exclude background\n",
        "            \n",
        "            for cls in unique_classes:\n",
        "                cls_pixels = np.sum(mask == cls)\n",
        "                relative_size = (cls_pixels / total_pixels) * 100\n",
        "                class_sizes[cls].append(relative_size)\n",
        "    \n",
        "    return class_sizes\n",
        "\n",
        "print(\"Analyzing object sizes...\")\n",
        "class_sizes = analyze_object_sizes(train_ids, max_samples=250)\n",
        "\n",
        "# Calculate statistics\n",
        "size_stats = {}\n",
        "for cls, sizes in class_sizes.items():\n",
        "    if cls < len(VOC_CLASSES):\n",
        "        size_stats[VOC_CLASSES[cls]] = {\n",
        "            'mean': np.mean(sizes),\n",
        "            'median': np.median(sizes),\n",
        "            'min': np.min(sizes),\n",
        "            'max': np.max(sizes),\n",
        "            'count': len(sizes)\n",
        "        }\n",
        "\n",
        "# Sort by mean size\n",
        "sorted_stats = sorted(size_stats.items(), key=lambda x: x[1]['mean'], reverse=True)\n",
        "\n",
        "# Visualize\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Box plot for top classes\n",
        "top_classes = [item[0] for item in sorted_stats[:12]]  # Top 12 by mean size\n",
        "box_data = [class_sizes[VOC_CLASSES.index(cls)] for cls in top_classes]\n",
        "\n",
        "bp = ax1.boxplot(box_data, labels=top_classes, patch_artist=True)\n",
        "for patch, cls_name in zip(bp['boxes'], top_classes):\n",
        "    cls_idx = VOC_CLASSES.index(cls_name)\n",
        "    if cls_idx < len(VOC_COLORMAP):\n",
        "        patch.set_facecolor([c/255.0 for c in VOC_COLORMAP[cls_idx]])\n",
        "        patch.set_alpha(0.7)\n",
        "\n",
        "ax1.set_ylabel('Relative Size (% of Image)')\n",
        "ax1.set_xlabel('Class')\n",
        "ax1.set_title('Distribution of Object Sizes (Top 12 Classes)')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Mean size comparison\n",
        "classes_for_bar = [item[0] for item in sorted_stats[:15]]\n",
        "mean_sizes = [item[1]['mean'] for item in sorted_stats[:15]]\n",
        "\n",
        "bars = ax2.barh(range(len(classes_for_bar)), mean_sizes, edgecolor='black', alpha=0.7)\n",
        "ax2.set_yticks(range(len(classes_for_bar)))\n",
        "ax2.set_yticklabels(classes_for_bar)\n",
        "ax2.set_xlabel('Mean Relative Size (% of Image)')\n",
        "ax2.set_title('Average Object Size by Class (Top 15)')\n",
        "ax2.invert_yaxis()\n",
        "\n",
        "# Color bars\n",
        "for i, cls_name in enumerate(classes_for_bar):\n",
        "    cls_idx = VOC_CLASSES.index(cls_name)\n",
        "    if cls_idx < len(VOC_COLORMAP):\n",
        "        bars[i].set_color([c/255.0 for c in VOC_COLORMAP[cls_idx]])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nObject Size Statistics (% of image):\")\n",
        "print(\"-\" * 70)\n",
        "for cls_name, stats in sorted_stats[:10]:\n",
        "    print(f\"{cls_name:15s} - Mean: {stats['mean']:5.2f}%, Median: {stats['median']:5.2f}%, \"\n",
        "          f\"Range: [{stats['min']:5.2f}%, {stats['max']:5.2f}%]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 10. Dataset Summary\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"PASCAL VOC 2012 SEMANTIC SEGMENTATION DATASET - SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nðŸ“Š DATASET SIZE:\")\n",
        "print(f\"  â€¢ Training images: {len(train_ids)}\")\n",
        "print(f\"  â€¢ Validation images: {len(val_ids)}\")\n",
        "print(f\"  â€¢ Total images: {len(trainval_ids)}\")\n",
        "\n",
        "print(\"\\nðŸŽ¨ CLASSES:\")\n",
        "print(f\"  â€¢ Total number of classes: {len(VOC_CLASSES)} (20 object classes + background)\")\n",
        "print(f\"  â€¢ Classes: {', '.join(VOC_CLASSES[1:])}\")\n",
        "\n",
        "if dimensions:\n",
        "    print(\"\\nðŸ“ IMAGE DIMENSIONS:\")\n",
        "    print(f\"  â€¢ Width range: {min(widths)} - {max(widths)} pixels (mean: {np.mean(widths):.0f})\")\n",
        "    print(f\"  â€¢ Height range: {min(heights)} - {max(heights)} pixels (mean: {np.mean(heights):.0f})\")\n",
        "    print(f\"  â€¢ Aspect ratio range: {min(aspect_ratios):.2f} - {max(aspect_ratios):.2f}\")\n",
        "\n",
        "if class_counts:\n",
        "    top_3_classes = class_counts.most_common(3)\n",
        "    print(\"\\nðŸ† MOST FREQUENT CLASSES (in sampled images):\")\n",
        "    for i, (cls, count) in enumerate(top_3_classes, 1):\n",
        "        print(f\"  {i}. {VOC_CLASSES[cls]}: appears in {count} images\")\n",
        "\n",
        "if sorted_classes:\n",
        "    print(\"\\nðŸŽ¯ PIXEL COVERAGE (from sampled images):\")\n",
        "    for i, (cls, pct) in enumerate(sorted_classes[:3], 1):\n",
        "        print(f\"  {i}. {VOC_CLASSES[cls]}: {pct:.2f}% of all pixels\")\n",
        "\n",
        "if num_classes_per_img:\n",
        "    print(\"\\nðŸ§© SEGMENTATION COMPLEXITY:\")\n",
        "    print(f\"  â€¢ Average classes per image: {np.mean(num_classes_per_img):.2f}\")\n",
        "    print(f\"  â€¢ Range: {min(num_classes_per_img)} - {max(num_classes_per_img)} classes per image\")\n",
        "\n",
        "print(\"\\nðŸ’¡ KEY INSIGHTS:\")\n",
        "print(\"  â€¢ The dataset exhibits class imbalance (background dominates)\")\n",
        "print(\"  â€¢ Images contain multiple objects with varying sizes\")\n",
        "print(\"  â€¢ Common co-occurrences reflect real-world scenarios (e.g., person+chair)\")\n",
        "print(\"  â€¢ Variable image dimensions require careful preprocessing\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EDA Complete! The dataset is ready for semantic segmentation tasks.\")\n",
        "print(\"=\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
