{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import VOCSegmentation\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pretrained FCN ResNet50 model with COCO+VOC weights\n",
        "model = torchvision.models.segmentation.fcn_resnet50(\n",
        "    weights=\"FCN_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1\"\n",
        ")\n",
        "model.eval()  # Set to evaluation mode (disables dropout, batchnorm in eval mode)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(f\"Model loaded on {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define transforms for input images\n",
        "# FCN ResNet50 expects: 3-channel RGB images, normalized with ImageNet stats\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize((520, 520)),  # Resize to consistent size\n",
        "    transforms.ToTensor(),  # Convert PIL Image to tensor [0,1], shape: [C, H, W]\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
        "])\n",
        "\n",
        "# Transform for target masks - just resize and convert to tensor\n",
        "target_transform = transforms.Compose([\n",
        "    transforms.Resize((520, 520), interpolation=transforms.InterpolationMode.NEAREST),  # Nearest neighbor for labels\n",
        "    transforms.PILToTensor()  # Shape: [1, H, W] with integer class labels\n",
        "])\n",
        "\n",
        "# Download PASCAL VOC 2012 segmentation dataset (validation split)\n",
        "dataset = VOCSegmentation(\n",
        "    root='./data',\n",
        "    year='2012',\n",
        "    image_set='val',  # Use validation set\n",
        "    download=True,\n",
        "    transform=img_transform,\n",
        "    target_transform=target_transform\n",
        ")\n",
        "print(f\"Dataset loaded: {len(dataset)} images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.shape()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_miou(pred, target, num_classes=21):\n",
        "    \"\"\"\n",
        "    Compute mean Intersection-over-Union (mIoU)\n",
        "    \n",
        "    IoU = (True Positive) / (True Positive + False Positive + False Negative)\n",
        "    mIoU = average IoU across all classes\n",
        "    \n",
        "    Args:\n",
        "        pred: predicted segmentation mask [H, W] with class indices\n",
        "        target: ground truth mask [H, W] with class indices\n",
        "        num_classes: number of classes (21 for VOC: 20 objects + background)\n",
        "    \n",
        "    Returns:\n",
        "        mIoU: mean IoU score\n",
        "    \"\"\"\n",
        "    ious = []\n",
        "    pred = pred.cpu().numpy()\n",
        "    target = target.cpu().numpy()\n",
        "    \n",
        "    # Ignore class 255 (border/void class in VOC)\n",
        "    target[target == 255] = 0\n",
        "    \n",
        "    for cls in range(num_classes):\n",
        "        pred_cls = (pred == cls)\n",
        "        target_cls = (target == cls)\n",
        "        \n",
        "        intersection = np.logical_and(pred_cls, target_cls).sum()\n",
        "        union = np.logical_or(pred_cls, target_cls).sum()\n",
        "        \n",
        "        if union > 0:\n",
        "            ious.append(intersection / union)\n",
        "    \n",
        "    return np.mean(ious) if ious else 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run inference on a few validation images\n",
        "num_samples = 4\n",
        "mious = []\n",
        "\n",
        "fig, axes = plt.subplots(num_samples, 2, figsize=(12, 3 * num_samples))\n",
        "\n",
        "for i in range(num_samples):\n",
        "    # Get image and ground truth mask\n",
        "    img_tensor, target_tensor = dataset[i]\n",
        "    \n",
        "    # Add batch dimension: [C, H, W] -> [1, C, H, W]\n",
        "    img_batch = img_tensor.unsqueeze(0).to(device)\n",
        "    \n",
        "    # Run inference (no gradient computation needed)\n",
        "    with torch.no_grad():\n",
        "        output = model(img_batch)['out']  # Shape: [1, 21, H, W] (21 class scores per pixel)\n",
        "    \n",
        "    # Get predicted class per pixel: argmax over class dimension\n",
        "    pred_mask = output.argmax(1).squeeze(0)  # Shape: [H, W]\n",
        "    \n",
        "    # Compute mIoU\n",
        "    target_mask = target_tensor.squeeze(0)  # Shape: [H, W]\n",
        "    miou = compute_miou(pred_mask, target_mask)\n",
        "    mious.append(miou)\n",
        "    \n",
        "    # Denormalize image for visualization\n",
        "    img_display = img_tensor.cpu().numpy().transpose(1, 2, 0)\n",
        "    img_display = img_display * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "    img_display = np.clip(img_display, 0, 1)\n",
        "    \n",
        "    # Display original image\n",
        "    axes[i, 0].imshow(img_display)\n",
        "    axes[i, 0].set_title(f\"Original Image {i+1}\")\n",
        "    axes[i, 0].axis('off')\n",
        "    \n",
        "    # Display predicted segmentation mask\n",
        "    axes[i, 1].imshow(pred_mask.cpu().numpy(), cmap='tab20', vmin=0, vmax=20)\n",
        "    axes[i, 1].set_title(f\"Predicted Mask (mIoU: {miou:.3f})\")\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nMean mIoU across {num_samples} samples: {np.mean(mious):.3f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
